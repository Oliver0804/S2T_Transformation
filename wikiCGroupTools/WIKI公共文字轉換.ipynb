{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1af9debf-3e15-47d5-92e1-7e3b05a58c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的，\"佈局\"是台灣用詞的意思是\"佈局\"。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19aa208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3b3725-b2fd-42b7-8b11-ffea2c3d1920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file CGroup_IT_Data.csv has been created successfully in outputData.\n",
      "CSV file CGroup_Electronics_Data.csv has been created successfully in outputData.\n",
      "CSV file CGroup_IT_Temp_Data.csv has been created successfully in outputData.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_item(line):\n",
    "    line = line.strip()\n",
    "    if line.startswith(\"Item('\"):\n",
    "        term_start = line.find(\"Item('\") + 6\n",
    "        term_end = line.find(\"'\", term_start)\n",
    "        term = line[term_start:term_end]\n",
    "\n",
    "        translations_start = line.find(\"'\", term_end + 1) + 1\n",
    "        translations_end = line.rfind(\"')\")\n",
    "        translations = line[translations_start:translations_end].split(';')\n",
    "        \n",
    "        translation_dict = {}\n",
    "        for t in translations:\n",
    "            t = t.strip()\n",
    "            if '=>' in t:\n",
    "                key, rest = t.split('=>')\n",
    "                if ':' in rest:\n",
    "                    lang, trans = rest.split(':')\n",
    "                    lang = lang.strip()\n",
    "                    trans = trans.strip()\n",
    "                else:\n",
    "                    continue\n",
    "            elif ':' in t:\n",
    "                key, trans = t.split(':')\n",
    "                lang = key.strip()\n",
    "                trans = trans.strip()\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            if lang == 'zh-hans':\n",
    "                lang = 'zh-cn'\n",
    "            elif lang == 'zh-hant':\n",
    "                lang = 'zh-tw'\n",
    "                \n",
    "            translation_dict[lang] = trans\n",
    "        \n",
    "        return term, translation_dict\n",
    "    return None, None\n",
    "\n",
    "def process_file(file_path, output_path):\n",
    "    term_dict = {}\n",
    "    all_languages = set(['en'])\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            term, translations = parse_item(line)\n",
    "            if term:\n",
    "                if term not in term_dict:\n",
    "                    term_dict[term] = {'en': term}\n",
    "                for key in translations:\n",
    "                    term_dict[term][key] = translations[key]\n",
    "                all_languages.update(translations.keys())\n",
    "\n",
    "    language_order = ['en', 'zh-tw', 'zh-cn', 'zh-hk'] + sorted(all_languages - set(['en', 'zh-tw', 'zh-cn', 'zh-hk']))\n",
    "\n",
    "    output_filename = os.path.basename(file_path).replace('.txt', '_Data.csv')\n",
    "    output_full_path = os.path.join(output_path, output_filename)\n",
    "    \n",
    "    with open(output_full_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=language_order)\n",
    "        writer.writeheader()\n",
    "        for term_info in term_dict.values():\n",
    "            writer.writerow(term_info)\n",
    "\n",
    "    print(f\"CSV file {output_filename} has been created successfully in {output_path}.\")\n",
    "\n",
    "def process_all_files(input_dir, output_dir):\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(input_dir, file_name)\n",
    "            process_file(file_path, output_dir)\n",
    "\n",
    "# 目錄設定\n",
    "input_dir = 'wikiRawData'\n",
    "output_dir = 'outputData'\n",
    "\n",
    "# 確保輸出目錄存在\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 處理所有文件\n",
    "process_all_files(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995fc7b-a575-4cbc-81d8-d0cf3188e1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chinese_corrector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
